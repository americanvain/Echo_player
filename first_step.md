## 第一部分：PDF → TextSegment（独立后台 Agent）

### 目标

将 PDF 原文 转换为一组 连续、完整、不重不漏的 TextSegment，作为后续处理的唯一文本来源。

该步骤只做忠实识别与分段，不做总结、不改写、不推断。

### 输入

一本英文小说或文本类 PDF

允许使用具备 PDF 视觉/文本识别能力的大模型（例如 ollama 下的Qwen3-VL）

### 输出

多个 TextSegment

每个 TextSegment 同时写入磁盘为一个 .txt 文件

### TextSegment 数据结构

segment_id：从 1 开始的连续整数，严格递增

text：该段的完整原文文本

source_ref：该段对应的来源标识

当前阶段：pdf可以省略该参数

未来扩展：SRT 时间戳（例如 00:01:23–00:01:31）

### 文件存储规则

每个 TextSegment 单独存为一个 .txt 文件

文件名 =segment_id.txt 

文件内容 = text（不包含任何额外说明、标记或模型解释）

### 分段规则（必须遵守）

以段落为优先聚合单位

原文段落完整则不拆

段落过长才允许拆分

### 长度控制目标

推荐：每个 segment 约 300–800 词

可因原文自然段落略微超出或不足

### 连续性要求（极其重要）

当前 segment_id 必须紧接上一个 segment 的结束位置

不允许：

跳过原文内容

回退重新识别已处理内容

重复包含前一 segment 的文本

### 幻觉与一致性约束（强约束）

该 Agent 必须只输出 PDF 中真实存在的内容，并满足以下条件：

❌ 不得生成 PDF 原文中不存在的任何词、句或标点

❌ 不得对原文进行改写、总结、补充、推断

❌ 不得重复同一段文本到不同 segment

❌ 不得遗漏任何原文内容（除非是明确无文本意义的噪声）

若遇到：

页眉页脚

页码

OCR 噪声
→ 可以删除，但正文内容必须完整保留

### 长对话/上下文保护机制

为防止对话过长导致模型状态异常：

Agent 每次只处理有限范围的 PDF 内容

每次输出后：

明确记录当前处理到的 segment_id 与原文位置

下次调用必须从该位置继续

不允许基于“记忆中已处理内容”进行推断

## 第二部分：TextSegment → CandidateSentence

### 目标

从 TextSegment.text 中，按原文顺序抽取可用于学习的“句级单位”，必须忠实使用原文。

### 核心原则

只使用原文

❌ 不允许改写

❌ 不允许重组

❌ 不允许合成新句子

结合上下文确保意义完整

若一句依赖前后句才能成立，可保留原文句式

不要求脱离全文完全自洽，但必须是作者原本的完整表达

### 长度与价值处理规则

1️⃣ 过长句子

如果原文句子本身很长，但这是作者表达完整意义的必要形式

✅ 允许完整保留

❌ 不得人为拆分

2️⃣ 过短 / 非学习价值文本

以下内容不具有英语学习价值，但不得丢弃：

拟声词（如 bang, ugh）

符号

独立短语、残句

处理方式：

直接按原文顺序输出

不做筛选或跳过

使用户可以通过“下一句”快速前进到有学习价值的内容

### 输出顺序约束

输出顺序 必须严格等同于原文出现顺序

不得重排、合并、跳跃

## 第三部分：CandidateSentence → 语音（TTS）

### 目标

为每一句生成 接近真人、有情感的自然语音，用于听力与跟读。

### 语音要求

语音应：

自然

非机械

具备基本情绪起伏（不要求戏剧化）

支持参数：

语速可调（如 0.8x – 1.1x）

不需要解释发音规则，仅生成音频

### 输出

音频文件（如 .wav / .mp3）

同时返回音频时长（秒）

## 第四部分：UtteranceUnit（最终输出单元）

### 数据结构

unit_id：连续整数

text：一句原文文本

source_ref：

当前阶段：对应的 .txt 文件名（即 储存textSegment 的 文件名）

未来扩展：该剧对应的视频时间轴

audio：

path：音频文件路径

duration：音频时长（秒）